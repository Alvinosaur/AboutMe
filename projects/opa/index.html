<!DOCTYPE html>
<html lang="en">

<!-- Imports -->

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Personal Website">
  <meta name="author" content="Alvin Shek">

  <title>Learning  from  Physical  Human  Feedback:An  Object-Oriented  One-Shot  Adaptation  Method</title>

  <!-- Bootstrap Core CSS -->
  <link href="../../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom Fonts -->
  <link href="../../vendor/fontawesome-free/css/all.min.css" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,300italic,400italic,700italic"
    rel="stylesheet" type="text/css">
  <link href="../../vendor/simple-line-icons/css/simple-line-icons.css" rel="stylesheet">

  <!-- Custom CSS -->
  <link rel="stylesheet" href="../../css/project/wowchemy.min.css">
  <link rel="manifest" href="../../index.webmanifest">
  <link href="../../css/stylish-portfolio.css" rel="stylesheet">
  <link rel="icon" href="../../main_icon.svg">
  <link rel="apple-touch-icon" href="../../main_icon.svg">
  <link rel="canonical" href="https://alvinosaur.github.io/AboutMe/projects/idl_project">
  <link rel="alternate" hreflang="en-us" href="https://alvinosaur.github.io/AboutMe/projects/idl_project">

  <link rel="stylesheet" href="../../css/project/custom_project.css">

  <!-- Javascript -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>

  <!------------------------------------------------------------------------>

  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <meta name="description"
    content="In top-5 among 46 projects in the course @ CMU 11-785 - Introduction to Deep Learning (Fall 2020) - [Project Gallery](https://deeplearning.cs.cmu.edu/F20/gallery/gallery.html)">

  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

  <meta name="theme-color" content="hsl(267°, 95%, 76%)">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"
    integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css"
    integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css"
    crossorigin="anonymous" title="hl-light" disabled>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css"
    crossorigin="anonymous" title="hl-dark">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css"
    integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA=="
    crossorigin="anonymous">

  <link rel="stylesheet"
    href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">

</head>



<body id="page-top">

  <!-- Navigation -->
  <!-- <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
    <a class="navbar-brand js-scroll-trigger" href="#page-top">
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="https://alvinosaur.github.io/AboutMe/#about">About</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="https://alvinosaur.github.io/AboutMe/#projects">Projects</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger"
            href="https://alvinosaur.github.io/AboutMe/photography/main.html">Photography</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="https://alvinosaur.github.io/AboutMe/#contact_me">Contact Me</a>
        </li>
      </ul>
    </div>
  </nav> -->


  
  <div class="page-body bg-white">
    <article class="article article-project">

      <div class="article-container pt-3">
        <center>
        <h3>Learning from Physical Human Feedback: <br>An Object-Centric  One-Shot Adaptation Method</h3> 
      </center>
<!-- 
          <div class="table-like authors" style="justify-content:space-evenly;max-width:800px;margin:auto;">
            <div><center><span><a href="https://alvinosaur.github.io/AboutMe/" target="_blank"
              rel="noopener">Alvin Shek</a></span></center>
              <center><span><a href="https://ruichen.pub/" target="_blank"
                rel="noopener">Rui Chen</a></span></center>
                <center><span><a href="http://www.cs.cmu.edu/~cliu6/" target="_blank"
                  rel="noopener">Changliu Liu</a></span></center>
             </div>
    
          </div> -->

          <center>
            <!-- <br> -->
            <nobr><a href="https://alvinosaur.github.io/AboutMe/" target="_blank"
              rel="noopener">Alvin Shek</a></nobr>    <nobr><a href="https://ruichen.pub/" target="_blank"
                rel="noopener">Rui Chen</a></nobr>    <nobr><a href="http://www.cs.cmu.edu/~cliu6/" target="_blank"
                  rel="noopener">Changliu Liu</a></nobr>
                  <br>
            <nobr>Carnegie Mellon University</nobr>
            <!-- <img style="vertical-align:middle" src="mcp_teaser.png" width="100%" height="inherit">		 -->
          </center>

        <!-- <h4></h4> -->

        <div class="article-metadata">
<!-- 
          <span class="article-date">

            Feb 28, 2022
          </span> -->

        </div>

        <div class="btn-links mb-3">

          <a class="btn btn-outline-primary my-1 mr-1" href="https://youtu.be/rBi9v9m3wJ8" target="_blank"
            rel="noopener">
            Video
          </a>

          <a class="btn btn-outline-primary my-1 mr-1" href="https://arxiv.org/abs/2203.04951" target="_blank"
            rel="noopener">
            Paper
          </a>

          <a class="btn btn-outline-primary my-1 mr-1" href="" target="_blank" rel="noopener">
            Code (TBD)
          </a>

        </div>

      </div>
      <div class="article-header article-container featured-image-wrapper mt-4 mb-4"
        style="max-width: 720px; max-height: 369px;">
        <div style="position: relative">
          <div class="videoWrapper">
            <!-- Copy & Pasted from YouTube -->
            <!-- Source: https://css-tricks.com/fluid-width-video/ -->
            <iframe width="560" height="349" src="https://youtu.be/rBi9v9m3wJ8" frameborder="0" allowfullscreen></iframe>
            <!-- <img src="thumbnail.png" alt="" class="featured-image"> -->
          </div>
          <span class="article-header-caption"></span>
        </div>
      </div>
      <br>

      <div class="article-container">

        <div class="article-style">
          <font size="4">
          <p>
            For robots to be effectively deployed in novel environments and tasks, they must be able to understand the feedback expressed by humans during intervention. This can either correct undesirable behavior or indicate additional preferences. Existing methods either require repeated episodes of interactions or assume prior known reward features, which is data-inefficient and can hardly transfer to new tasks. We relax these assumptions by describing human tasks in terms of object-centric sub-tasks and interpreting physical interventions in <em>relation to specific objects</em>. Our method, Object Preference Adaptation (OPA), is composed of two key stages: 1) pre-training a base policy to produce a wide variety of behaviors, and 2) online-updating only certain weights in the model according to human feedback. The key to our fast, yet simple adaptation is that general interaction dynamics between agents and objects are fixed, and only object-specific preferences are updated. Our adaptation occurs online, requires only one human intervention (one-shot), and produces new behaviors never seen during training. Trained on cheap synthetic data instead of expensive human demonstrations, our policy demonstrates impressive adaptation to human perturbations on challenging, realistic tasks in our user study. 
          </p>
        </font>
        </div>

        <h3>Ablation Studies (Coming Soon)</h3>

        <h4>"Singularities" of Potential Fields</h4>
        <div class="article-style">
          <font size="4">
          <p>
            In Section 3-B of the paper, we mentioned how position relation network overall outputs a push-pull force on the agent. We allow 
            this direction to be freely determined by the network. Potential field methods also use this approach, but constrain the direction to be parallel to each agent-object vector. Only magnitude and sign of the vector can change. This may seem like an intuitive way to enforce structure in the network and reduce complexity, but this constraint fails during “singularities” where no orthogonal component is available to avoid an obstacle lying in the same direction as the goal.
            
            <div style="position: relative">
              <img src="forced_free.png" alt="" class="featured-image">
            </div>
            The two images compare "forced" and "free" direction behavior respectively at a single timestep with the light pink agent, blue expert, Notice on the left, since
            the red repulsor object lies directly on the path to the goal, 
            no orthogonal force component can help the agent avoid the 
            obstacle. On the right, however, the force direction contributed
            by the repulsor object has an orthogonal component, allowing
            the agent to avoid the repulsor. This is shown fully in the video below:
            <div style="position: relative">
              <video controls>
                <source src="forced_free.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
          </p>
        </font>
        </div>

        <h4>Scalability with Objects</h4>
        <div class="article-style">
          <font size="4">
          <p>
            One of our method's key advantages is scalability in the number of objects. Classical motion planners and trajectory optimization
            may 
            
            <div style="position: relative">
              <img src="forced_free.png" alt="" class="featured-image">
            </div>
            The two images compare "forced" and "free" direction behavior respectively at a single timestep with the light pink agent, blue expert, Notice on the left, since
            the red repulsor object lies directly on the path to the goal, 
            no orthogonal force component can help the agent avoid the 
            obstacle. On the right, however, the force direction contributed
            by the repulsor object has an orthogonal component, allowing
            the agent to avoid the repulsor. This is shown fully in the video below:
            <div style="position: relative">
              <video controls>
                <source src="forced_free.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
          </p>
        </font>
        </div>
      </div>
      <br>
    </article>
  </div>


</body>

</html>